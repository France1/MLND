\relax 
\citation{Mnih2013}
\citation{Mnih2015}
\citation{Mnih2016}
\citation{Sutton}
\citation{OpenAI}
\citation{Mnih2013}
\citation{Mnih2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Definition}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Project Overview}{1}}
\newlabel{sec:overview}{{1.1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Problem Statement}{1}}
\citation{Mnih2016}
\citation{OpenAI}
\citation{PongActions}
\citation{Mnih2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Metrics}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Analysis}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Exploration and Visualisation}{2}}
\newlabel{sec:data-exploration}{{2.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Algorithm and Techniques}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}DQN}{2}}
\citation{Williams1992}
\citation{Sutton}
\citation{Karpathy}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Pong frame.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pong-frame}{{1}{3}}
\newlabel{eq:BellmanEq}{{2}{3}}
\newlabel{eq:DQN-loss}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Policy Gradient}{3}}
\newlabel{eq:policy-gradient}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DQN algorithm\relax }}{4}}
\newlabel{fig:DQN_algorithm}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Policy gradient algorithm\relax }}{4}}
\newlabel{fig:PG_algorithm}{{3}{4}}
\citation{Mnih2015}
\citation{Karpathy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Benchmark}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance of a random agent, in blue the episode return and in red the moving average on a window of 10 episodes.\relax }}{5}}
\newlabel{fig:random-agent}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data preprocessing}{5}}
\citation{Jaromiru}
\citation{Mnih2013}
\citation{Karpathy}
\citation{Ecoffet}
\newlabel{fig:preprocessing-original}{{5a}{6}}
\newlabel{sub@fig:preprocessing-original}{{(a)}{a}}
\newlabel{fig:preprocessing-binary}{{5b}{6}}
\newlabel{sub@fig:preprocessing-binary}{{(b)}{b}}
\newlabel{fig:preprocessing-difference}{{5c}{6}}
\newlabel{sub@fig:preprocessing-difference}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Frame preprocessing: (a) current original frame, (b) binary image after cropping and down-sampling, and (c) difference between next frame and current frame.\relax }}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{6}}
\newlabel{fig:Preprocessing}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Implementation}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}DQN algorithm}{6}}
\citation{Ecoffet}
\newlabel{lst:DQN-agent}{{1}{7}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}DQN Agent definition}{7}}
\newlabel{lst:DQN-brain}{{2}{8}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}DQN Brain definition}{8}}
\newlabel{lst:DQN-environment}{{3}{8}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}DQN Environment definition}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Policy Gradient Agorithm}{9}}
\newlabel{lst:PG-agent}{{4}{9}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}Policy Gradient Agent definition}{9}}
\newlabel{lst:PG-brain}{{5}{10}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}Policy Gradient Brain definition}{10}}
\newlabel{lst:PG-brain}{{6}{11}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}Policy Gradient Brain definition}{11}}
\citation{Mnih2015}
\citation{Karpathy}
\citation{Mnih2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Refinement}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Reflection and improvement}{12}}
\bibcite{Mnih2013}{1}
\bibcite{Mnih2015}{2}
\newlabel{fig:DQN-learning}{{6a}{13}}
\newlabel{sub@fig:DQN-learning}{{(a)}{a}}
\newlabel{fig:PG-learning}{{6b}{13}}
\newlabel{sub@fig:PG-learning}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Agent training performance for (a) DQN and (b) Policy Gradient algorithm. In blue the return obtained at the end of an episode, and in red the moving average calculated in a window of 10 episodes.\relax }}{13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{13}}
\newlabel{fig:Preprocessing}{{6}{13}}
\bibcite{Mnih2016}{3}
\bibcite{Sutton}{4}
\bibcite{OpenAI}{5}
\bibcite{Jaromiru}{6}
\bibcite{Williams1992}{7}
\bibcite{Karpathy}{8}
\bibcite{Ecoffet}{9}
